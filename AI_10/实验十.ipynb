{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd334ce",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验十：卷积神经网络</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79567a9b",
   "metadata": {},
   "source": [
    "这次实验课分两周完成，部分实验内容涉及下周的理论课，同学们可继续熟悉pytorch框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab3007",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:卷积神经网络介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa49e9",
   "metadata": {},
   "source": [
    "输入尺寸为m$\\times$n,卷积核大小为f,步幅为s,填充为p,则输出尺寸为$\\lfloor \\frac{m+2p-f}{s}+1 \\rfloor$ $\\times$ $\\lfloor \\frac{n+2p-f}{s}+1 \\rfloor$  \n",
    "\n",
    "$$( m \\times n )* ( f \\times f ) = \\lfloor \\frac{m+2p-f}{s}+1 \\rfloor \\times \\lfloor \\frac{n+2p-f}{s}+1 \\rfloor$$  \n",
    "例子:输入尺寸为6$\\times$6,卷积核大小为f,步幅默认为1,填充为0,则输出尺寸为$\\lfloor \\frac{6+2\\times0-3}{1}+1 \\rfloor$ $\\times$ $\\lfloor \\frac{6+2\\times0-3}{1}+1 \\rfloor$=$4\\times4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82e9e5",
   "metadata": {},
   "source": [
    "卷积层的运算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0ed66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  3., -1., -1.],\n",
      "        [ 0.,  3., -1., -2.],\n",
      "        [ 0.,  3., -1., -2.],\n",
      "        [ 0.,  3., -2., -3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn  as  nn\n",
    "\n",
    "def conv_calculate(X,K):\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h ,j:j+w]*K).sum()\n",
    "    return Y\n",
    "#X是进入卷积层的原始数据\n",
    "X=torch.tensor([[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                [0.0,1.0,0.0,0.0,0.0,0.0],\n",
    "                [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                [0.0,1.0,0.0,0.0,1.0,1.0]])\n",
    "#K是卷积核，即卷积层的参数之一\n",
    "K=torch.tensor([[1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0]])\n",
    "#conv_calculate(X,K)即X经过该卷积核进行运算完成后得到的结果\n",
    "print(conv_calculate(X,K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c5b34",
   "metadata": {},
   "source": [
    "手动实现二维卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1684ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        #kernel_size:卷积核大小\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        #偏置\n",
    "        self.bias   = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self,x):\n",
    "        return conv_calculate(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5967920",
   "metadata": {},
   "source": [
    "Pytorch中实现卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入的通道数目（必须设置的参数）\n",
    "in_channels=1\n",
    "#输出的通道数目（必须设置的参数）\n",
    "out_channels=1\n",
    "#卷积核大小（必须设置的参数）\n",
    "kernel_size=3\n",
    "#其余参数皆为可选的参数，如stride代表步幅，padding代表填充，后面会进行介绍\n",
    "pytorch_conv2d=nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0)\n",
    "\n",
    "#初始化该卷积层后，会自动随机分配参数。可以输出其中的参数\n",
    "print(pytorch_conv2d.state_dict())\n",
    "#这里我们生成输入数据R1\n",
    "R1=torch.tensor([[1.0,2.0,3.0,4.0,5.0,6.0],\n",
    "                 [2.0,3.0,4.0,5.0,6.0,7.0],\n",
    "                 [3.0,4.0,5.0,6.0,7.0,8.0],\n",
    "                 [4.0,5.0,6.0,7.0,8.0,9.0],\n",
    "                 [5.0,6.0,7.0,8.0,9.0,10.0],\n",
    "                 [6.0,7.0,8.0,9.0,10.0,11.0]])\n",
    "#reshape函数：将数据转换为指定维度以及大小的数据\n",
    "#这里使用reshape函数是由于卷积函数的输入必须是四维数据\n",
    "#其中第一个维度代表着批量大小，第二个维度代表着输入通道数。这里由于我们的X为单通道的一个样本，所以两个维度的参数值均设置为1\n",
    "R1=R1.reshape((1,1,6,6))\n",
    "#将数据R1通过该网络，得到输出数据R2\n",
    "R2=pytorch_conv2d(R1)\n",
    "print(R2,R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a02e8",
   "metadata": {},
   "source": [
    "卷积层的简单应用：检测图像中不同颜色的边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05873c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=torch.tensor([[10.0,10.0,10.0,0.0,0.0,0.0],\n",
    "                [10.0,10.0,10.0,0.0,0.0,0.0],\n",
    "                [10.0,10.0,10.0,0.0,0.0,0.0],\n",
    "                [10.0,10.0,10.0,0.0,0.0,0.0],\n",
    "                [10.0,10.0,10.0,0.0,0.0,0.0],\n",
    "                [10.0,10.0,10.0,0.0,0.0,0.0]])\n",
    "K=torch.tensor([[1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0]])#卷积核\n",
    "Y=conv_calculate(X,K)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e76fe",
   "metadata": {},
   "source": [
    "卷积网络中卷积核是可以学习的参数  \n",
    "例子：已知X和X经过某卷积层后得到的结果Y，学习由X生成Y的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5be2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_test=nn.Conv2d(1,1,kernel_size=(3,3),bias=False)\n",
    "X=X.reshape((1,1,6,6))\n",
    "Y=Y.reshape((1,1,4,4))\n",
    "#我们通过下列的操作去学习由X生成Y的卷积核\n",
    "\n",
    "#学习率\n",
    "lr=0.000001 \n",
    "for i in range(10):\n",
    "    Y_hat=conv_test(X)\n",
    "    #损失函数\n",
    "    l=(Y_hat-Y)**2\n",
    "    #梯度清零\n",
    "    conv_test.zero_grad()\n",
    "    l.sum().backward()\n",
    "    #简易的梯度下降\n",
    "    conv_test.weight.data[:] -= lr * conv_test.weight.grad \n",
    "    print(f'round{i+1},loss:{l.sum():.6f}')\n",
    "print(\"学习得到的卷积核：\",conv_test.weight.data.reshape(3,3))\n",
    "print(\"实际正确的卷积核\",torch.tensor([[1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0],\n",
    "                [1.0,0.0,-1.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a804d",
   "metadata": {},
   "source": [
    "填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d24060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在所有侧边填充1个像素\n",
    "X=torch.rand(size=(4,4))\n",
    "\n",
    "#2维变4维\n",
    "X=X.reshape((1,1)+X.shape)\n",
    "print(X,X.shape)\n",
    "\n",
    "#卷积核大小为2X2,填充像素为1\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=2,padding=1) \n",
    "Y=conv2d(X)\n",
    "\n",
    "\n",
    "#所以未填充前计算结果大小为3X3，填充后大小为5X5\n",
    "\n",
    "Y=Y.reshape(Y.shape[2:])\n",
    "print(Y,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead9cc3",
   "metadata": {},
   "source": [
    "步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.rand(size=(8,8))\n",
    "#2维变4维\n",
    "X=X.reshape((1,1)+X.shape)\n",
    "print(X,X.shape)\n",
    "\n",
    "#卷积核大小为2X2,填充像素为1,步幅为2\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=2,padding=1,stride=2) \n",
    "Y=conv2d(X)\n",
    "\n",
    "#所以未填充前计算结果大小为3X3，填充后大小为5X5\n",
    "Y=Y.reshape(Y.shape[2:])\n",
    "print(Y,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6a3b7",
   "metadata": {},
   "source": [
    "多通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15125c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多通道的卷积的运算方式\n",
    "def corr2d_multi_calculate(X,K):\n",
    "    return sum(conv_calculate(x,k) for x,k in zip(X,K))\n",
    "#将之前的X从单通道变为二通道\n",
    "X=torch.tensor([[[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0]],\n",
    "                [[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0]]])\n",
    "#相应的卷积核也变为二通道\n",
    "K=torch.tensor([[[1.0,0.0,-1.0],\n",
    "                 [1.0,0.0,-1.0],\n",
    "                 [1.0,0.0,-1.0]],\n",
    "                [[1.0,0.0,-1.0],\n",
    "                 [1.0,0.0,-1.0],\n",
    "                 [1.0,0.0,-1.0]]])\n",
    "print(corr2d_multi_calculate(X,K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa7c4d",
   "metadata": {},
   "source": [
    "Pytorch中实现多通道卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=2 #输入的通道数目（必须设置的参数）\n",
    "\n",
    "#这里大家可以修改输出通道数来查看输出的变化\n",
    "out_channels=2 #输出的通道数目（必须设置的参数）\n",
    "\n",
    "\n",
    "kernel_size=3 #卷积核大小（必须设置的参数）\n",
    "#其余参数皆为可选的参数，如stride代表步幅，padding代表填充，后面会进行介绍\n",
    "pytorch_conv2d=nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0)\n",
    "\n",
    "#初始化该卷积层后，会自动随机分配参数。可以输出其中的参数\n",
    "print(pytorch_conv2d.state_dict())\n",
    "#这里我们生成输入数据R1\n",
    "R1=torch.tensor([[[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0]],\n",
    "                [[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,0.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,0.0,1.0],\n",
    "                 [0.0,1.0,0.0,0.0,1.0,1.0]]])\n",
    "#其这里由于我们的R1为两通道的一个样本，所以批量为1，输入通道为2\n",
    "R1=R1.reshape((1,2,6,6))\n",
    "#将数据R1通过该网络，得到输出数据R2\n",
    "R2=pytorch_conv2d(R1)\n",
    "print(R2,R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f74cc",
   "metadata": {},
   "source": [
    "池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b25593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn  as  nn\n",
    "#最大池化层\n",
    "def pool_use(X,pool_size):\n",
    "    p_h,p_w=pool_size\n",
    "    Y=torch.zeros((X.shape[0]-p_h+1,X.shape[1]-p_w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=X[i:i+p_h,j:j+p_w].max()\n",
    "    return Y\n",
    "X=torch.tensor([[0.0,1.0,0.0,0.0,1.0,0.0],\n",
    "                [0.0,2.0,0.0,0.0,0.0,1.0],\n",
    "                [0.0,1.0,3.0,0.0,0.0,0.0],\n",
    "                [0.0,1.0,0.0,0.0,1.0,1.0],\n",
    "                [0.0,1.0,0.0,0.0,6.0,1.0],\n",
    "                [0.0,1.0,0.0,0.0,1.0,1.0]])\n",
    "print(pool_use(X,(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5319efe",
   "metadata": {},
   "source": [
    "Pytorch中的池化层实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871be22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#常用参数：kernel_size：最大池化的窗口大小，stride步长，padding:填充\n",
    "#需要设置通道数\n",
    "X=X.reshape((1,1,6,6))\n",
    "pool_nn=nn.MaxPool2d(kernel_size=2,stride=1)\n",
    "print(pool_nn(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448b0be",
   "metadata": {},
   "source": [
    "MNIST数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16250b3d",
   "metadata": {},
   "source": [
    "MNIST数据集由10个类别(即数字0到9)的手写数字图片所组成，包括60000个训练样本和10000个测试样本，每个样本都是单通道图片,由28x28x1个像素点组成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc31a91",
   "metadata": {},
   "source": [
    "这里加载一张MNIST数据集中的一个样本，一个样本即为一张图片，我们使用pytorch框架将其转换为tensor类型，其shape即为[1,28,28]，代表每个样本都是单通道图片,由28x28个像素点组成，其对应的label为7"
   ]
  },
  {
   "attachments": {
    "MNIST%E6%95%B0%E6%8D%AE.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "51a6f6fa",
   "metadata": {},
   "source": [
    "![MNIST%E6%95%B0%E6%8D%AE.PNG](attachment:MNIST%E6%95%B0%E6%8D%AE.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c056d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision 库是服务于pytorch深度学习框架的,用来生成图片,视频数据集,和一些流行的模型类和预训练模型\n",
    "#可以调用torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)来下载MNIST数据集\n",
    "#参数root代表存放数据集的根目录\n",
    "#参数train代表是否为训练数据集\n",
    "#参数Transform代表一个函数/转换，它接收PIL图像并返回转换后的版本。这里我们pytorch框架中只接收tensor类型数据，所以需要进行转换\n",
    "#参数download如果为true，则从Internet下载数据集并将其放在根目录中。如果已下载数据集，则不会再次下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data #加载数据用\n",
    "#在使用上面的torchvision.datasets调用完数据集后，再使用torch.utils.data的DataLoader方法来将数据集划分为许多batch，下面是三个主要参数\n",
    "#dataset： 加载数据的数据集。\n",
    "#batch_size：每个batch加载多少个样本(默认: 1)。\n",
    "#shuffle：设置为True时会在每个epoch重新打乱数据(默认: False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac732951",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c168ff",
   "metadata": {},
   "source": [
    "任务1：使用LeNet网络训练MNIST数据集，保存每轮epoch中每个batch的训练损失以及每次网络更新后在测试集上的准确率，之后分别作两张图来将数据可视化。神经网络构建后，通过超参数的调整尽可能获得更高的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8015179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as  plt\n",
    "import torch.nn  as  nn\n",
    "import torch.utils.data as Data \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffcaf0",
   "metadata": {},
   "source": [
    "搭建LeNet神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95351e2",
   "metadata": {},
   "source": [
    "LeNet实现：  \n",
    "输入层：输入为28x28x1  \n",
    "卷积层1：卷积核大小：5x5；输出大小：28x28x6 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "最大池化层1：卷积核大小：2x2；步幅大小：2；输出大小：14x14x6    \n",
    "卷积层2：卷积核大小：5x5；输出大小：10x10x16  \n",
    "最大池化层2：卷积核大小：2x2；步幅大小：2；输出大小：5x5x16  \n",
    "全连接层1：输入大小：5x5x16；输出大小：120  \n",
    "全连接层2：输入大小：120；输出大小：84  \n",
    "全连接层3：输入大小：84；输出大小：10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfcecb",
   "metadata": {},
   "source": [
    "计算图如下：\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "     -> linear -> relu -> linear -> relu -> linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f57b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,1,2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    # 定义前向传播过程，输入为x\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        \n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net=LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dbcf36",
   "metadata": {},
   "source": [
    "设置超参数，包括训练轮数，批次大小，学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb72975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "batch = 100\n",
    "rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568dbdd",
   "metadata": {},
   "source": [
    "定义该次网络训练中需要使用的损失函数和优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25865f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75bced",
   "metadata": {},
   "source": [
    "构建MNIST数据集，并按照训练批次大小完成训练集和测试集的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11946416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='mnist_data', train=True, transform=torchvision.transforms.ToTensor(), target_transform=None, download=False)\n",
    "test_dataset = torchvision.datasets.MNIST(root='mnist_data', train=False, transform=torchvision.transforms.ToTensor(), target_transform=None, download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16b7ac",
   "metadata": {},
   "source": [
    "开始训练完成并更新，保存每轮中每个batch的训练损失，以及每轮网络更新后的准确率  \n",
    "如果训练效果较差，可以对超参数以及神经网络进行适当调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf93d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "correct = []\n",
    "for i in range(epoch):\n",
    "    train_correct=0\n",
    "    tem=0\n",
    "    for img, label in train_loader:\n",
    "        out = net(img)\n",
    "        loss=criterion(out,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tem+=loss \n",
    "        _, m = out.max(1)    \n",
    "        num_correct = (m == label).sum().item()  \n",
    "        acc = num_correct / img.shape[0]\n",
    "        train_correct += acc\n",
    "    train_loss.append(tem / len(train_loader))\n",
    "    correct.append(train_correct / len(train_loader))\n",
    "    \n",
    "    \n",
    "    tem = 0\n",
    "    for img, label in test_loader:\n",
    "        out = net(img)\n",
    "        loss = criterion(out, label)\n",
    "        \n",
    " \n",
    "        tem += loss\n",
    "    test_loss.append(tem / len(test_loader))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c80cb",
   "metadata": {},
   "source": [
    "利用上次实验中的画图方法将训练损失和准确率进行作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2915f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# for i in range(len(train_loss)):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     train_loss[i]=train_loss[i].detach().numpy()  \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# for i in range(len(test_loss)):\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     test_loss[i]=test_loss[i].detach().numpy()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_loss\u001b[49m)), train_loss)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(correct)),correct,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  \n",
    "# for i in range(len(train_loss)):\n",
    "#     train_loss[i]=train_loss[i].detach().numpy()  \n",
    "# for i in range(len(test_loss)):\n",
    "#     test_loss[i]=test_loss[i].detach().numpy()\n",
    "plt.title(\"train_loss\")\n",
    "plt.plot(np.arange(len(train_loss)), train_loss)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(correct)),correct,color='green',label='correct')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c21aa",
   "metadata": {},
   "source": [
    "任务2：Alexnet较为复杂，训练时间长，感兴趣的同学可以课后尝试训练，这里不做要求训练。只要求写出网络结构的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c3cb5",
   "metadata": {},
   "source": [
    "AlexNet实现：  \n",
    "输入层：输入为28x28x1  \n",
    "卷积层1：卷积核大小：3x3；输出大小：28x28x32 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "最大池化层1：卷积核大小：2x2；步幅大小：2；输出大小：14x14x32  \n",
    "ReLu1  \n",
    "卷积层2：卷积核大小：3x3；输出大小：14x14x64 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "最大池化层2：卷积核大小：2x2；步幅大小：2；输出大小：7x7x64   \n",
    "ReLu2  \n",
    "卷积层3：卷积核大小：3x3；输出大小：7x7x128 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "卷积层4：卷积核大小：3x3；输出大小：7x7x256 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "卷积层5：卷积核大小：3x3；输出大小：7x7x256 （为了保证输入和输出大小一致，所以这里需要加入填充）  \n",
    "最大池化层3：卷积核大小：2x2；步幅大小：2；输出大小：3x3x256   \n",
    "ReLu3   \n",
    "全连接层1：输入大小：3x3x256；输出大小：1024    \n",
    "全连接层2：输入大小：1024；输出大小：512    \n",
    "全连接层3：输入大小：512；输出大小：10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41beeb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1,1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1,1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv3 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.conv4 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.conv5 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1 = nn.Linear(3*3*256, 1024)  \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool3(F.relu(x))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net=AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de556c17",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af4c65",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ee601",
   "metadata": {},
   "source": [
    "二、本次实验分两周完成，所以实验报告于下下周五实验课(6月10号前)上课前提交报告  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff171e9b",
   "metadata": {},
   "source": [
    "实验十(卷积网络)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/998b6c0c23d04152bcd41a7760e595cc/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096d66f",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
