{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验五:随机森林</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edc145",
   "metadata": {},
   "source": [
    "本次实验为编写集成学习中的随机森林算法。在上一次实验中，我们已经学会了如何构建一棵ID3决策树。在本次实验，我们将以上一次决策树代码的基础上，结合集成学习中的并行化生成分类模型的思想，构建多棵决策树，组成随机森林。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef6f7c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# tem = set(range(5))\n",
    "# print(len(tem))\n",
    "# # tem = list(tem)\n",
    "# # tem\n",
    "# a = np.random.choice(list(tem), replace=True, size=10)\n",
    "# for i in a:\n",
    "#     print(i)\n",
    "# a = np.array([1,2,3])\n",
    "b = np.array([3,4,5])\n",
    "b[-1]\n",
    "# temlist = []\n",
    "# temlist.append(a)\n",
    "# temlist.append(b)\n",
    "# temlist = np.array(temlist)\n",
    "# temlist[:,0]\n",
    "# int(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c19637",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:函数介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302e25c",
   "metadata": {},
   "source": [
    "介绍一些在数据采样和属性集采样的过程中可以用到的随机函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ba5e802",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# np.random.choice函数从一个一维数组中随机采样\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# np.random.shuffle函数对一个数组/矩阵按照第一维进行洗牌\u001b[39;00m\n",
      "File \u001b[1;32mmtrand.pyx:946\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# np.random.choice函数从一个一维数组中随机采样\n",
    "x = np.array([1,2,3,4])\n",
    "y = np.random.choice(x, replace=True, size=10)\n",
    "print(y)\n",
    "\n",
    "# np.random.shuffle函数对一个数组/矩阵按照第一维进行洗牌\n",
    "x = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14]])\n",
    "np.random.shuffle(x)\n",
    "print(x)\n",
    "\n",
    "# DataFrame对象的sample函数可以随机采样n个数据或者采样比例为frac的数据\n",
    "x = np.array([[0,0,0],[1,1,1],[2,2,2],[3,3,3],[4,4,4]])\n",
    "frame = pd.DataFrame(x)\n",
    "print(frame.sample(n=2))\n",
    "print(frame.sample(frac=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca268aef",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64283722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365ec76",
   "metadata": {},
   "source": [
    "本次实验承接上次实验，实现随机森林。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f63e5a",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 采用自助采样法对训练数据集'train_titanic.csv'进行采样，生成$n$个训练数据集($n$自行设定)。自助采样法是指，每次从原本数据集中【有放回】地随机采样一个数据，重复进行$m$次，就生成一个有$m$个数据的训练数据集($m$是原本数据集的数据个数)。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b674f7a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "\n",
    "# Bootstrap 采样\n",
    "n = 10\n",
    "m = len(train_frame)\n",
    "new_train = []\n",
    "\n",
    "for i in range(n):\n",
    "    tem = train_frame.sample(1)\n",
    "    for j in range(1,m):\n",
    "        tem = tem.append(train_frame.sample(1))      \n",
    "    new_train.append(tem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6819a7",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 对上次实验的best_split函数进行修改，改成先从属性集$A$中先随机选取$k$个属性构成属性集$A'$，再从$A'$中选取最佳划分的属性。($k$是一个整数，一般取$max(round(log_2 d),1)$, 其中$d$是$A$的元素的个数)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b55657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label):\n",
    "    label = label.reshape(len(label),1)\n",
    "    counter = Counter(label[:,0])\n",
    "    a=np.unique(label[:,0])\n",
    "    ent=0\n",
    "    m = len(label)\n",
    "    for i in range(len(a)):\n",
    "        ent -= counter[a[i]]/m*np.log2(counter[a[i]]/m)\n",
    "    return ent\n",
    "\n",
    "def split(feature, label, dimension):\n",
    "    label = label.reshape(len(label),1)\n",
    "    a=np.unique(feature[:,dimension])\n",
    "    split_feature = []\n",
    "    split_label = []\n",
    "    for i in range(len(a)):\n",
    "        split_feature.append([])\n",
    "        split_label.append([])\n",
    "    for i in range(len(label)):\n",
    "        for j in range(len(a)):\n",
    "            if feature[i,dimension]==a[j]:\n",
    "                split_feature[j].append(feature[i,:])\n",
    "                split_label[j].append(label[i,:])\n",
    "    for i in range(len(a)):\n",
    "        split_feature[i] = np.array(split_feature[i])\n",
    "        split_label[i] = np.array(split_label[i])\n",
    "    split_feature = np.array(split_feature)\n",
    "    split_label = np.array(split_label)\n",
    "    return split_feature,split_label\n",
    "\n",
    "def best_split(D, A):\n",
    "    best_entropy = -100\n",
    "    best_dimension = -1\n",
    "    ladi = D.shape[1]-1\n",
    "    tot = entropy(D[:,ladi])\n",
    "    for i in A:\n",
    "        tem = tot\n",
    "        split_feature,split_label=split(D,D[:,D.shape[1]-1],i)\n",
    "        for j in range(len(split_label)):\n",
    "            tem-=len(split_label[j])/len(D)*entropy(split_label[j])\n",
    "        if tem>best_entropy:\n",
    "            best_entropy=tem\n",
    "            best_dimension=i\n",
    "    return best_dimension\n",
    "\n",
    "def new_best_split(D,A):\n",
    "    k = int(max(round(np.log2(len(A))),1))\n",
    "    A_new = np.random.choice(list(A), replace=False, size=k)\n",
    "    result = best_split(D,A_new)\n",
    "    return result\n",
    "\n",
    "def same(D,A):\n",
    "    tem = np.sum(D,axis=0)/len(D)\n",
    "    for i in A:\n",
    "        if all(D[:,i] != tem[i]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5da06",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 对上次实验完成的决策树类进行如下修改：①predict函数不需要计算预测准确率，要返回数据集D的预测标签；②每个属性的可能取值possible_value不从采样的数据集中取，而是从原本数据集'train_titanic.csv'中取，以防止在预测过程中出现决策树在训练过程中未见过的属性取值。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a275ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记下所有属性可能的取值\n",
    "D = np.array(train_frame)\n",
    "A = set(range(D.shape[1] - 1))\n",
    "possible_value = {}\n",
    "for every in A:\n",
    "    possible_value[every] = np.unique(D[:, every])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d03dbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树结点类\n",
    "class Node:\n",
    "    def __init__(self, isLeaf=True, label=-1, index=-1):\n",
    "        self.isLeaf = isLeaf # isLeaf表示该结点是否是叶结点\n",
    "        self.label = label # label表示该叶结点的label（当结点为叶结点时有用）\n",
    "        self.index = index # index表示该分支结点的划分属性的序号（当结点为分支结点时有用）\n",
    "        self.children = {} # children表示该结点的所有孩子结点，dict类型，方便进行决策树的搜索\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        self.children[val] = node #为当前结点增加一个划分属性的值为val的孩子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12e76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树类\n",
    "class DTree:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None #决策树的根结点\n",
    "        self.possible_value = possible_value # 用于存储每个属性可能的取值\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    TreeGenerate函数用于递归构建决策树，伪代码参照课件中的“Algorithm 1 决策树学习基本算法”\n",
    "    '''\n",
    "    def TreeGenerate(self, D, A):\n",
    "        \n",
    "        # 生成结点 node\n",
    "        node = Node()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if D中样本全属于同一类别C then\n",
    "        #     将node标记为C类叶结点并返回\n",
    "        # end if\n",
    "        ladi = D.shape[1]-1\n",
    "        counter = Counter(D[:,ladi])\n",
    "        if counter[0] == len(D):\n",
    "            node.label = 0\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        elif counter[1] == len(D):\n",
    "            node.label = 1\n",
    "            node.isLeaf = True \n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if A = Ø OR D中样本在A上取值相同 then\n",
    "        #     将node标记叶结点，其类别标记为D中样本数最多的类并返回\n",
    "        # end if\n",
    "        if (len(A)==0) or same(D,A):\n",
    "            if counter[0]>=counter[1]:\n",
    "                node.label = 0\n",
    "            else:\n",
    "                node.label = 1\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 从A中选择最优划分属性a_star\n",
    "        # （选择信息增益最大的属性，用到上面实现的best_split函数）\n",
    "        a_star = new_best_split(D, A)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for a_star 的每一个值a_star_v do\n",
    "        #     为node 生成每一个分支；令D_v表示D中在a_star上取值为a_star_v的样本子集\n",
    "        #     if D_v 为空 then\n",
    "        #         将分支结点标记为叶结点，其类别标记为D中样本最多的类\n",
    "        #     else\n",
    "        #         以TreeGenerate(D_v,A-{a_star}) 为分支结点\n",
    "        #     end if\n",
    "        # end for\n",
    "        tem = Counter(D[:,a_star])\n",
    "\n",
    "        node.isLeaf = False\n",
    "        node.index = a_star\n",
    "\n",
    "        for a_star_v in self.possible_value[a_star]:\n",
    "            D_v = []\n",
    "            newnode = Node()                       \n",
    "            for i in range(len(D)):\n",
    "                if D[i,a_star] == a_star_v:\n",
    "                    D_v.append(D[i,:])\n",
    "            D_v = np.array(D_v)\n",
    "            \n",
    "            if(len(D_v)==0):\n",
    "                newnode.label = 0\n",
    "                newnode.isleaf = True\n",
    "                           ############\n",
    "            else:\n",
    "                newnode = self.TreeGenerate(D_v,A-{a_star})\n",
    "            node.addNode(a_star_v,newnode)\n",
    "    \n",
    "        return node\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    train函数可以做一些数据预处理（比如Dataframe到numpy矩阵的转换，提取属性集等），并调用TreeGenerate函数来递归地生成决策树\n",
    "    '''\n",
    "    def train(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        A = set(range(D.shape[1] - 1)) # 属性集A\n",
    "        self.tree_root = self.TreeGenerate(D, A) # 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    predict函数对测试集D进行预测，输出预测标签\n",
    "    '''\n",
    "    def predict(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        \n",
    "#         #对于D中的每一行数据d，从当前结点x=self.tree_root开始，当当前结点x为分支结点时，\n",
    "#         #则搜索x的划分属性为该行数据相应的属性值的孩子结点（即x=x.children[d[x.index]]），不断重复，\n",
    "#         #直至搜索到叶结点，该叶结点的label就是数据d的预测label\n",
    "        result = []\n",
    "        for i in range(len(D)):\n",
    "            x = self.tree_root\n",
    "            d = D[i,:]\n",
    "            while x.isLeaf == False:\n",
    "\n",
    "                x=x.children[d[x.index]]\n",
    "            result.append(x.label)\n",
    "        result = np.array(result)\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d040b",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 生成$n$棵决策树实例，每棵决策树对上面生成的$n$个训练数据集中的一个数据集进行训练。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13d5c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Your code here -------\n",
    "dtree = []\n",
    "for i in range(n):\n",
    "    new_tree = DTree()\n",
    "    new_tree.train(new_train[i])\n",
    "    dtree.append(new_tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469222d",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">5) 用训练完成的$n$棵决策树分别对测试数据集'test_titanic.csv'进行预测。采用相对多数投票法$H(x)=C_{\\mathop{\\arg\\max}_{j} \\sum_{i=1}^T h_i^j(x)}$来对各棵决策树的预测结果进行结合。输出结合的预测结果的准确率。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9896a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8415841584158416"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame = pd.read_csv('test_titanic.csv')\n",
    "\n",
    "# ----- Your code here -------\n",
    "\n",
    "test = np.array(test_frame)\n",
    "totallabel = []\n",
    "for i in range(n):\n",
    "    totallabel.append(dtree[i].predict(test_frame))\n",
    "totallabel = np.array(totallabel)\n",
    "correct = 0\n",
    "for i in range(len(test)):\n",
    "    counter1 = Counter(totallabel[:,i])\n",
    "    if counter1[1] >= counter1[0]:\n",
    "        if test[i,test.shape[1]-1] == 1:\n",
    "            correct += 1\n",
    "    else:\n",
    "        if test[i,test.shape[1]-1] == 0:\n",
    "            correct += 1\n",
    "correct/len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f62e5",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1b059",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a115318",
   "metadata": {},
   "source": [
    "二、因为下周放假冲了一次理论课，本次实验做两周，实验报告下下周（4月15号前）交  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2724b",
   "metadata": {},
   "source": [
    "实验五(随机森林)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/3c4acbb1e9a044c48fec14e2fdb97b56/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1e971",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
