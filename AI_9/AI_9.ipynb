{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59a56ee",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验九：神经网络中的前向传播与后向传播</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc83e5b",
   "metadata": {},
   "source": [
    "本次实验的主要内容是了解和熟悉PyTorch框架以及神经网络中的前向传播和后向传播在PyTorch框架下的操作，分两周完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "62f100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf0fe",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:PyTorch介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444420a4",
   "metadata": {},
   "source": [
    "PyTorch是最受机器学习从业者欢迎的深度学习框架之一。PyTorch 受欢迎的一些原因是它易于使用、有动态计算图，以及它比其他框架(如Tensorflow)更“Pythonic”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a394db6",
   "metadata": {},
   "source": [
    "这里介绍一小部分PyTorch常用的库和函数，更多需求可参阅[PyTorch官方教程](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)以及[PyTorch官方文档](https://pytorch.org/docs/stable/index.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6fae149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch # 导入的是 torch 而不是 pytorch\n",
    "print(torch.__version__) # 输出当前pytorch的版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392780bb",
   "metadata": {},
   "source": [
    "1.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904623e4",
   "metadata": {},
   "source": [
    "Tensor与NumPy中的ndarray很相似，但Tensor可以利用GPU来加速计算，并且Tensor可以进行自动求导(意味着很多时候不需要再手撕梯度了)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23642996",
   "metadata": {},
   "source": [
    "1) Tensor的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38cdf3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0065e-44, 8.1275e-44, 7.2868e-44],\n",
      "        [7.9874e-44, 8.1275e-44, 7.2868e-44]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0.3024, 0.5774, 0.1551, 0.9481],\n",
      "        [0.4857, 0.2014, 0.3203, 0.6147],\n",
      "        [0.3807, 0.3568, 0.0197, 0.2718]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个未初始化的Tensor\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "# 从一个列表创建Tensor\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 创建一个随机Tensor\n",
    "x = torch.rand([3, 4])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全零Tensor\n",
    "x = torch.zeros([2, 3])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全一Tensor\n",
    "x = torch.ones([2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f354fd4",
   "metadata": {},
   "source": [
    "2) Tensor的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8070a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n",
      "tensor([[-5, -3, -1],\n",
      "        [ 1,  3,  5]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [6, 5, 4],\n",
      "        [3, 2, 1]])\n",
      "tensor([[1, 2, 3, 6, 5, 4],\n",
      "        [4, 5, 6, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 加减法\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.tensor([[6,5,4],[3,2,1]])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "\n",
    "# 对应位置相乘\n",
    "print(x * y)\n",
    "print(x.mul(y))\n",
    "\n",
    "# 矩阵乘法\n",
    "print(x.matmul(y.T))\n",
    "print(x @ y.T)\n",
    "\n",
    "# reshape\n",
    "print(x.reshape(3, 2))\n",
    "\n",
    "# 拼接\n",
    "print(torch.cat([x,y], dim=0)) # 纵向拼接\n",
    "print(torch.cat([x,y], dim=1)) # 横向拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95961cee",
   "metadata": {},
   "source": [
    "3) Tensor与ndarray的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1269212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 从Tensor转换到ndarray\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "\n",
    "# Tensor与ndarray是共享空间的\n",
    "x[:]=0\n",
    "print(y)\n",
    "\n",
    "# 从ndarray到Tensor\n",
    "z = torch.from_numpy(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c36a7",
   "metadata": {},
   "source": [
    "2.自动求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf56db",
   "metadata": {},
   "source": [
    "torch中的autograd包会为Tensor上的所有运算提供自动微分。它是一个define-by-run的框架，意味着后向传播取决于你的代码是如何运行的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec80e8",
   "metadata": {},
   "source": [
    "torch.Tensor是这个包的中心类。如果把它的属性.requires_grad置为True，那么他就会开始跟踪基于它的所有运算。当你的计算结束后，可以调用.backward()来自动计算所有的梯度。该tensor的梯度会累加到.grad属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b30fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]]) tensor(1.)\n",
      "tensor([0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966])\n",
      "tensor(4.)\n",
      "tensor(5.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2.]], requires_grad=True) # 把requires_grad设为True, 开始跟踪基于它的所有运算\n",
    "b = torch.tensor([[3.],[4.]])\n",
    "c = torch.tensor(5., requires_grad=True)\n",
    "y = a @ b + c\n",
    "y.backward() #自动计算梯度\n",
    "print(a.grad, c.grad) #输出叶子节点a和c的梯度\n",
    "\n",
    "# 可支持多种运算求梯度，如torch.mean(),torch.sum()等\n",
    "a = torch.ones(20, requires_grad=True)\n",
    "z = torch.sum(torch.sigmoid(a))\n",
    "z.backward()\n",
    "print(a.grad)\n",
    "\n",
    "# 多次求梯度时梯度会累加，可使用tensor.grad.zero_()进行手动清零\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "z = x + 3\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "x.grad.zero_()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d22808",
   "metadata": {},
   "source": [
    "3. 神经网络（官方教程中的例子）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348fd34a",
   "metadata": {},
   "source": [
    "（以下内容在本周不做要求，有兴趣的同学可以提前熟悉）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c1916",
   "metadata": {},
   "source": [
    "一个典型的神经网络训练过程如下：\n",
    "* 定义一个有一些可学习参数(或权重)的神经网络\n",
    "* 遍历数据集的输入\n",
    "* 用神经网络来处理输入\n",
    "* 计算损失函数\n",
    "* 传播梯度到网络的参数中\n",
    "* 更新网络的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe8502",
   "metadata": {},
   "source": [
    "1) 定义一个有一些可学习参数(或权重)的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3dcc32",
   "metadata": {},
   "source": [
    "torch.nn.Module类是所有神经网络模块的基类，我们可以通过定义一个继承torch.nn.Module的类来自定义一个神经网络模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b1bdd",
   "metadata": {},
   "source": [
    "自定义自己的网络的时候，需要重写\\_\\_init\\_\\_构造函数以及forward()前向传播方法。一般把网络中具有可学习参数的层(如卷积层、全连接层等)放在\\_\\_init\\_\\_()中；而不具有可学习参数的层(如池化层、ReLU层等)可写在\\_\\_init\\_\\_()中，也可写在forward()中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a097c",
   "metadata": {},
   "source": [
    "backward()后向传播方法一般不用自己定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad991204",
   "metadata": {},
   "source": [
    "以下是一个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "207b6433",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 继承自nn.Module\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 调用父类的构造函数\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        # 其中in_features表示有多少个输入，out_features表示该层有多少个神经元\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87620d9c",
   "metadata": {},
   "source": [
    "该神经网络中可学习的参数可以通过net.parameters()访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c2a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce625e41",
   "metadata": {},
   "source": [
    "2) 遍历数据集的输入(本例用一个随机输入来进行说明)并用神经网络来处理输入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398f05b",
   "metadata": {},
   "source": [
    "torch.nn只支持小批量，输入中的第0维应该是本次输入的样本个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b733263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0038,  0.0268, -0.0327,  0.0031, -0.1221, -0.0418,  0.0214, -0.0229,\n",
      "         -0.0131,  0.0845]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 随机生成一个输入送入net中，除了第0维是样本个数外，其余维度要与forward()参数中x的维度对应上\n",
    "input = torch.randn(1, 1, 32, 32) # 1个样本，该样本是有1个通道的32×32的图像\n",
    "out = net(input) # 进行一次forward()前向传播\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da3400",
   "metadata": {},
   "source": [
    "3) 计算损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "af35f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8864, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # 假装是输入input对应的标签\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "# nn模块提供了许多种类的损失函数，如nn.CrossEntropyLoss()、nn.MSELoss()等等\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428f7ce",
   "metadata": {},
   "source": [
    "计算图如下：\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> flatten -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e9ada5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x00000175454750A0>\n",
      "<AddmmBackward object at 0x0000017545475BE0>\n",
      "<AccumulateGrad object at 0x00000175454750A0>\n"
     ]
    }
   ],
   "source": [
    "# 查看计算图中的函数\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df4af9",
   "metadata": {},
   "source": [
    "4) 传播梯度到网络的参数中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "854ee4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0184, -0.0076, -0.0011, -0.0118,  0.0048,  0.0126])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # 由于网络中的参数默认会累积梯度，在重新计算梯度前需要清零\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "# 进行一次后向传播\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc342d6e",
   "metadata": {},
   "source": [
    "5) 更新网络的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27058a",
   "metadata": {},
   "source": [
    "可选择手动更新参数或者用PyTorch提供的优化器来更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7187507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用梯度下降法(手动)更新net中的参数\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06d237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用PyTorch的优化器来更新net中的参数\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 在每次循环中应该做的事:\n",
    "optimizer.zero_grad()   # 把梯度清零\n",
    "output = net(input) # 进行一次前向传播\n",
    "loss = criterion(output, target) # 计算误差\n",
    "loss.backward() # 后向传播\n",
    "optimizer.step()    # 进行一次参数更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be2d1f",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验内容</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5214e5",
   "metadata": {},
   "source": [
    "[Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)是一个关于红酒品质的数据集，总共有1599个样本，每个样本包含11个(都是连续的)特征以及1个标签，每个标签的取值是连续的。本次实验已经按照8：2的比例划分成了训练数据集'wine_train.csv'以及测试数据集'wine_test.csv'，且每个数据集都已经做了归一化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9ccac",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 读入训练数据集'wine_train.csv'与测试数据集'wine_test.csv'。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c759660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1279, 11])\n",
      "torch.Size([1279, 1])\n",
      "torch.Size([320, 11])\n",
      "torch.Size([320, 1])\n"
     ]
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "train_frame = pd.read_csv('wine_train.csv')\n",
    "test_frame = pd.read_csv('wine_test.csv')\n",
    "\n",
    "train = np.array(train_frame)\n",
    "test = np.array(test_frame)\n",
    "train_input = torch.from_numpy(train[:,0:11])\n",
    "train_label = torch.from_numpy(train[:,11:12])\n",
    "test_input = torch.from_numpy(test[:,0:11])\n",
    "test_label = torch.from_numpy(test[:,11:12])\n",
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77619fd",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 利用线性层和激活函数搭建一个神经网络，要求输入和输出维度与数据集维度一致，而神经网络深度、隐藏层大小、激活函数种类等超参数自行调整。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26359bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Your code here --\n",
    "\n",
    "\n",
    "# 继承自nn.Module\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 7)  \n",
    "        self.fc2 = nn.Linear(7, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "mynet = MyNet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b706eea",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 用梯度下降法进行模型参数更新，记下每轮迭代中的训练损失和测试损失。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad2f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (fc1): Linear(in_features=11, out_features=7, bias=True)\n",
      "  (fc2): Linear(in_features=7, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "mynet = mynet.double()\n",
    "print(mynet)\n",
    "ite=20\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(mynet.parameters(), lr=0.1)\n",
    "\n",
    "for i in range(ite):\n",
    "#     net.zero_grad()\n",
    "    optimizer.zero_grad()   \n",
    "    train_output = mynet(train_input)\n",
    "    test_output = mynet(test_input)\n",
    "    loss = criterion(train_output, train_label)\n",
    "    train_loss.append(loss)\n",
    "    test_loss.append(criterion(test_output, test_label))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ff45e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 画出训练损失和测试损失关于迭代轮数的折线图。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba3071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "y = np.arange(1,ite+1)\n",
    "\n",
    "plt.plot(y,train_loss,color='red',label='train')\n",
    "plt.plot(y,test_loss,color='blue',label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970666c3",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> 补充说明：学院购买了几台带有GPU的服务器，可高效进行深度学习，比个人电脑训练速度更快，有算力需求的同学可联系助教申请使用账号。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaceea0",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564e8a6",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af5b08",
   "metadata": {},
   "source": [
    "二、实验报告下下周五实验课(5月27号前)上课前提交报告  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e73e3",
   "metadata": {},
   "source": [
    "实验九(神经网络)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/82f1e06ef43f4c1faf33a0ad2f44786e/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db7ee4",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604c348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
