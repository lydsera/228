{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验五:随机森林</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edc145",
   "metadata": {},
   "source": [
    "本次实验为编写集成学习中的随机森林算法。在上一次实验中，我们已经学会了如何构建一棵ID3决策树。在本次实验，我们将以上一次决策树代码的基础上，结合集成学习中的并行化生成分类模型的思想，构建多棵决策树，组成随机森林。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6f7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c19637",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:函数介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302e25c",
   "metadata": {},
   "source": [
    "介绍一些在数据采样和属性集采样的过程中可以用到的随机函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba5e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 3 2 2 3 4 2]\n",
      "[[ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [12 13 14]\n",
      " [ 3  4  5]]\n",
      "1\n",
      "   0  1  2\n",
      "0  0  0  0\n",
      "1  1  1  1\n",
      "2\n",
      "   0  1  2\n",
      "2  2  2  2\n",
      "1  1  1  1\n"
     ]
    }
   ],
   "source": [
    "# np.random.choice函数从一个一维数组中随机采样\n",
    "x = np.array([1,2,3,4])\n",
    "y = np.random.choice(x, replace=True, size=10)\n",
    "print(y)\n",
    "\n",
    "# np.random.shuffle函数对一个数组/矩阵按照第一维进行洗牌\n",
    "x = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14]])\n",
    "np.random.shuffle(x)\n",
    "print(x)\n",
    "\n",
    "# DataFrame对象的sample函数可以随机采样n个数据或者采样比例为frac的数据\n",
    "x = np.array([[0,0,0],[1,1,1],[2,2,2],[3,3,3],[4,4,4]])\n",
    "frame = pd.DataFrame(x)\n",
    "print(1)\n",
    "print(frame.sample(n=2))\n",
    "print(2)\n",
    "print(frame.sample(frac=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca268aef",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365ec76",
   "metadata": {},
   "source": [
    "本次实验承接上次实验，实现随机森林。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f63e5a",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 采用自助采样法对训练数据集'train_titanic.csv'进行采样，生成$n$个训练数据集($n$自行设定)。自助采样法是指，每次从原本数据集中【有放回】地随机采样一个数据，重复进行$m$次，就生成一个有$m$个数据的训练数据集($m$是原本数据集的数据个数)。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b674f7a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  sibsp  Parch  Pclass  Survived\n",
       "17      0      0      0       2         1\n",
       "878     0      1      0       1         0\n",
       "107     0      0      0       3         1\n",
       "472     1      0      0       2         0\n",
       "209     0      0      0       1         1\n",
       "...   ...    ...    ...     ...       ...\n",
       "1002    1      1      0       1         0\n",
       "252     0      0      0       1         0\n",
       "981     0      0      0       1         0\n",
       "179     0      0      0       3         0\n",
       "941     1      0      1       1         0\n",
       "\n",
       "[1009 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "\n",
    "n = 10\n",
    "m = len(train_frame)\n",
    "new_data = []\n",
    "\n",
    "for i in range(n):\n",
    "    tem = train_frame.sample(1)\n",
    "    for j in range(1,m):\n",
    "        tem = tem.append(train_frame.sample(1))      ####不能只append要赋值  服了\n",
    "    new_data.append(tem)\n",
    "# Bootstrap 采样\n",
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d43192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6819a7",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 对上次实验的best_split函数进行修改，改成先从属性集$A$中先随机选取$k$个属性构成属性集$A'$，再从$A'$中选取最佳划分的属性。($k$是一个整数，一般取$max(round(log_2 d),1)$, 其中$d$是$A$的元素的个数)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label):\n",
    "    label = label.reshape(len(label),1)\n",
    "    counter = Counter(label[:,0])\n",
    "    a=np.unique(label[:,0])\n",
    "    ent=0\n",
    "    m = len(label)\n",
    "    for i in range(len(a)):\n",
    "        ent -= counter[a[i]]/m*np.log2(counter[a[i]]/m)\n",
    "    return ent\n",
    "\n",
    "def split(feature, label, dimension):\n",
    "    label = label.reshape(len(label),1)\n",
    "    a=np.unique(feature[:,dimension])\n",
    "    split_feature = []\n",
    "    split_label = []\n",
    "    for i in range(len(a)):\n",
    "        split_feature.append([])\n",
    "        split_label.append([])\n",
    "    for i in range(len(label)):\n",
    "        for j in range(len(a)):\n",
    "            if feature[i,dimension]==a[j]:\n",
    "                split_feature[j].append(feature[i,:])\n",
    "                split_label[j].append(label[i,:])\n",
    "    for i in range(len(a)):\n",
    "        split_feature[i] = np.array(split_feature[i])\n",
    "        split_label[i] = np.array(split_label[i])\n",
    "    split_feature = np.array(split_feature)\n",
    "    split_label = np.array(split_label)\n",
    "    return split_feature,split_label\n",
    "\n",
    "def best_split(D, A):\n",
    "    best_entropy = -100\n",
    "    best_dimension = -1\n",
    "    ladi = D.shape[1]-1    \n",
    "    tot = entropy(D[:,ladi])\n",
    "    for i in A:\n",
    "        tem = tot\n",
    "        split_feature,split_label=split(D,D[:,D.shape[1]-1],i)\n",
    "        for j in range(len(split_label)):\n",
    "            tem-=len(split_label[j])/len(D)*entropy(split_label[j])\n",
    "        if tem>best_entropy:\n",
    "            best_entropy=tem\n",
    "            best_dimension=i\n",
    "    return best_dimension\n",
    "\n",
    "def new_best_split(D,A):\n",
    "    A_frame = pd.DataFrame(A)\n",
    "    d = len(A)\n",
    "    k = max(round(math.log(d,2)),1)\n",
    "    A_new = np.array(A_frame.sample(k))\n",
    "    return best_split(D,A_new)\n",
    "\n",
    "def same(D,A):\n",
    "    tem = np.sum(D,axis=0)/len(D)\n",
    "    for i in A:\n",
    "        if all(D[:,i] != tem[i]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5da06",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 对上次实验完成的决策树类进行如下修改：①predict函数不需要计算预测准确率，要返回数据集D的预测标签；②每个属性的可能取值possible_value不从采样的数据集中取，而是从原本数据集'train_titanic.csv'中取，以防止在预测过程中出现决策树在训练过程中未见过的属性取值。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a275ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记下所有属性可能的取值\n",
    "D = np.array(train_frame)\n",
    "A = set(range(D.shape[1] - 1))\n",
    "possible_value = {}\n",
    "for every in A:\n",
    "    possible_value[every] = np.unique(D[:, every])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03dbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树结点类\n",
    "class Node:\n",
    "    def __init__(self, isLeaf=True, label=-1, index=-1):\n",
    "        self.isLeaf = isLeaf # isLeaf表示该结点是否是叶结点\n",
    "        self.label = label # label表示该叶结点的label（当结点为叶结点时有用）\n",
    "        self.index = index # index表示该分支结点的划分属性的序号（当结点为分支结点时有用）\n",
    "        self.children = {} # children表示该结点的所有孩子结点，dict类型，方便进行决策树的搜索\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        self.children[val] = node #为当前结点增加一个划分属性的值为val的孩子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树类\n",
    "class DTree:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None #决策树的根结点\n",
    "        self.possible_value = possible_value # 用于存储每个属性可能的取值\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    TreeGenerate函数用于递归构建决策树，伪代码参照课件中的“Algorithm 1 决策树学习基本算法”\n",
    "    '''\n",
    "    def TreeGenerate(self, D, A):\n",
    "\n",
    "        # 生成结点 node\n",
    "        node = Node()\n",
    "        \n",
    "        ladi = D.shape[1]-1\n",
    "#         print(ladi)\n",
    "#         print(D)\n",
    "#         print(D[:,ladi])\n",
    "        counter = Counter(D[:,ladi])\n",
    "\n",
    "        # if D中样本全属于同一类别C then\n",
    "        #     将node标记为C类叶结点并返回\n",
    "        # end if\n",
    "        if counter[0] == len(D):\n",
    "            \n",
    "            node.label = 0\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        elif counter[1] == len(D):\n",
    "            \n",
    "            node.label = 1\n",
    "            node.isLeaf = True \n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if A = Ø OR D中样本在A上取值相同 then\n",
    "        #     将node标记叶结点，其类别标记为D中样本数最多的类并返回\n",
    "        # end if\n",
    "        \n",
    "        if (len(A)==0) or same(D,A):\n",
    "            \n",
    "            if counter[0]>=counter[1]:\n",
    "                \n",
    "                node.label = 0\n",
    "            else:\n",
    "                \n",
    "                node.label = 1\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 从A中选择最优划分属性a_star\n",
    "        # （选择信息增益最大的属性，用到上面实现的best_split函数）\n",
    "      \n",
    "        a_star = new_best_split(D, A)\n",
    "#         print(a_star.shape)\n",
    "#         print(a_star[0])\n",
    "        # for a_star 的每一个值a_star_v do\n",
    "        #     为node 生成每一个分支；令D_v表示D中在a_star上取值为a_star_v的样本子集\n",
    "        #     if D_v 为空 then\n",
    "        #         将分支结点标记为叶结点，其类别标记为D中样本最多的类\n",
    "        #     else\n",
    "        #         以TreeGenerate(D_v,A-{a_star}) 为分支结点\n",
    "        #     end if\n",
    "        # end for\n",
    "        tem = Counter(D[:,a_star[0]])\n",
    "        tem1 = np.unique(D[:,a_star[0]])\n",
    "        node.isLeaf = False\n",
    "        node.index = a_star[0]\n",
    "        for a_star_v in tem1:\n",
    "#             print(a_star_v)\n",
    "            newnode = Node(False)\n",
    "            if(tem[a_star_v]==0):\n",
    "                newnode.label = 0\n",
    "                newnode.isleaf = True\n",
    "                           ############\n",
    "            else:\n",
    "                D_v = []\n",
    "                for i in range(len(D)):\n",
    "                    if D[i,a_star[0]] == a_star_v:\n",
    "                        D_v.append(D[i,:])\n",
    "                D_v = np.array(D_v)\n",
    "                \n",
    "                newnode = self.TreeGenerate(D_v,A-{a_star[0]})\n",
    "            node.children[a_star_v] = newnode\n",
    "        \n",
    "        \n",
    "        return node    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    train函数可以做一些数据预处理（比如Dataframe到numpy矩阵的转换，提取属性集等），并调用TreeGenerate函数来递归地生成决策树\n",
    "    '''\n",
    "    def train(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "#         print(D)\n",
    "        A = set(range(D.shape[1] - 1)) # 属性集A\n",
    "        self.tree_root = self.TreeGenerate(D, A) # 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    predict函数对测试集D进行预测，输出预测标签\n",
    "    '''\n",
    "    def predict(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        result = []\n",
    "#         #对于D中的每一行数据d，从当前结点x=self.tree_root开始，当当前结点x为分支结点时，\n",
    "#         #则搜索x的划分属性为该行数据相应的属性值的孩子结点（即x=x.children[d[x.index]]），不断重复，\n",
    "#         #直至搜索到叶结点，该叶结点的label就是数据d的预测label\n",
    "        for i in range(len(D)):\n",
    "            x = self.tree_root\n",
    "            d = D[i,:]\n",
    "            while x.isLeaf == False:\n",
    "#                 print(x.children)\n",
    "                x=x.children[d[x.index]]\n",
    "            result.append(x.label)\n",
    "        result = np.array(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d040b",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 生成$n$棵决策树实例，每棵决策树对上面生成的$n$个训练数据集中的一个数据集进行训练。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13d5c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  sibsp  Parch  Pclass  Survived\n",
      "17      0      0      0       2         1\n",
      "878     0      1      0       1         0\n",
      "107     0      0      0       3         1\n",
      "472     1      0      0       2         0\n",
      "209     0      0      0       1         1\n",
      "...   ...    ...    ...     ...       ...\n",
      "1002    1      1      0       1         0\n",
      "252     0      0      0       1         0\n",
      "981     0      0      0       1         0\n",
      "179     0      0      0       3         0\n",
      "941     1      0      1       1         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "195    1      0      0       1         1\n",
      "176    0      3      1       3         0\n",
      "876    0      0      0       3         0\n",
      "503    0      0      1       3         1\n",
      "746    0      0      0       3         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "914    0      0      0       1         0\n",
      "883    0      0      0       3         0\n",
      "792    0      0      2       3         0\n",
      "686    0      0      0       3         0\n",
      "178    0      0      0       2         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "46     0      1      0       3         0\n",
      "317    0      0      0       2         0\n",
      "10     1      1      1       3         1\n",
      "449    0      0      0       1         1\n",
      "825    0      1      0       1         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "838    0      1      1       2         0\n",
      "560    0      2      0       3         0\n",
      "950    1      1      0       3         0\n",
      "345    1      0      0       2         1\n",
      "516    1      0      0       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "946    0      0      0       1         0\n",
      "759    1      0      0       1         0\n",
      "592    1      1      0       3         0\n",
      "553    1      0      1       1         1\n",
      "568    0      0      0       3         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "586    0      0      0       2         0\n",
      "6      0      0      0       1         0\n",
      "584    0      0      0       3         0\n",
      "6      0      0      0       1         0\n",
      "71     1      5      2       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "180    1      8      2       3         0\n",
      "444    0      0      0       3         1\n",
      "581    0      0      0       3         0\n",
      "93     0      1      2       3         0\n",
      "193    0      1      1       2         1\n",
      "..   ...    ...    ...     ...       ...\n",
      "374    1      3      1       3         0\n",
      "668    1      2      0       1         0\n",
      "651    0      0      0       3         0\n",
      "521    0      0      0       3         1\n",
      "640    1      0      2       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "107    0      0      0       3         1\n",
      "735    0      0      0       1         0\n",
      "201    0      8      2       3         0\n",
      "137    0      1      0       1         0\n",
      "339    0      0      0       1         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "741    1      0      1       1         0\n",
      "252    0      0      0       1         0\n",
      "564    0      0      0       2         0\n",
      "902    0      0      0       3         0\n",
      "717    0      0      0       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "      Sex  sibsp  Parch  Pclass  Survived\n",
      "617     1      0      1       1         0\n",
      "419     1      0      2       3         0\n",
      "459     0      0      0       3         0\n",
      "307     1      1      0       1         1\n",
      "13      0      1      5       3         0\n",
      "...   ...    ...    ...     ...       ...\n",
      "1006    0      0      0       3         0\n",
      "13      0      1      5       3         0\n",
      "157     0      0      0       3         0\n",
      "627     1      0      0       3         0\n",
      "592     1      1      0       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "167    1      1      4       3         0\n",
      "448    1      2      1       3         1\n",
      "969    0      0      0       1         0\n",
      "968    0      0      0       2         0\n",
      "538    0      0      0       3         1\n",
      "..   ...    ...    ...     ...       ...\n",
      "264    1      0      0       3         0\n",
      "375    1      1      0       1         1\n",
      "572    0      0      0       1         0\n",
      "170    0      0      0       1         0\n",
      "628    1      0      0       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "274    1      0      0       3         1\n",
      "381    1      0      2       3         1\n",
      "904    1      0      0       3         0\n",
      "626    0      0      0       3         0\n",
      "404    1      0      0       3         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "216    1      0      0       3         1\n",
      "569    0      1      1       3         1\n",
      "53     1      1      0       2         1\n",
      "725    0      0      0       3         0\n",
      "308    0      1      0       2         0\n",
      "\n",
      "[1009 rows x 5 columns]\n",
      "     Sex  sibsp  Parch  Pclass  Survived\n",
      "561    0      1      0       2         0\n",
      "594    0      0      0       3         0\n",
      "287    0      0      0       3         0\n",
      "202    0      0      0       3         0\n",
      "600    0      2      0       3         0\n",
      "..   ...    ...    ...     ...       ...\n",
      "922    0      0      0       1         0\n",
      "339    0      0      0       1         0\n",
      "836    0      1      0       1         0\n",
      "678    1      0      0       3         0\n",
      "314    0      1      1       2         0\n",
      "\n",
      "[1009 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ----- Your code here -------\n",
    "dtree = []\n",
    "for i in range(n):\n",
    "    new_tree = DTree()\n",
    "#     tem = new_data[i]\n",
    "    print(new_data[i])\n",
    "    new_tree.train(new_data[i])\n",
    "    \n",
    "\n",
    "    dtree.append(new_tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469222d",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">5) 用训练完成的$n$棵决策树分别对测试数据集'test_titanic.csv'进行预测。采用相对多数投票法$H(x)=C_{\\mathop{\\arg\\max}_{j} \\sum_{i=1}^T h_i^j(x)}$来对各棵决策树的预测结果进行结合。输出结合的预测结果的准确率。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9896a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m totallabel \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m----> 6\u001b[0m     totallabel\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdtree\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_frame\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m totallabel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(totallabel)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# predictlabel = []\u001b[39;00m\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mDTree.predict\u001b[1;34m(self, D)\u001b[0m\n\u001b[0;32m    122\u001b[0m             d \u001b[38;5;241m=\u001b[39m D[i,:]\n\u001b[0;32m    123\u001b[0m             \u001b[38;5;28;01mwhile\u001b[39;00m x\u001b[38;5;241m.\u001b[39misLeaf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m#                 print(x.children)\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m                 x\u001b[38;5;241m=\u001b[39m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    126\u001b[0m             result\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[0;32m    127\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result)\n",
      "\u001b[1;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "test_frame = pd.read_csv('test_titanic.csv')\n",
    "test = np.array(test_frame)\n",
    "# ----- Your code here -------\n",
    "totallabel = []\n",
    "for i in range(n):\n",
    "    totallabel.append(dtree[i].predict(test_frame))\n",
    "totallabel = np.array(totallabel)\n",
    "# predictlabel = []\n",
    "correct = 0\n",
    "for i in range(len(test)):\n",
    "    counter1 = Counter(totallabel[:,i])\n",
    "    if counter1[1] >= counter1[0]:\n",
    "        if test[i,test.shape[1]-1] == 1:\n",
    "            correct += 1\n",
    "    else:\n",
    "        if test[i,test.shape[1]-1] == 0:\n",
    "            correct += 1\n",
    "correct/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f62e5",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1b059",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a115318",
   "metadata": {},
   "source": [
    "二、因为下周放假冲了一次理论课，本次实验做两周，实验报告下下周（4月15号前）交  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2724b",
   "metadata": {},
   "source": [
    "实验五(随机森林)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/3c4acbb1e9a044c48fec14e2fdb97b56/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1e971",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
