{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验四:决策树</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67a4f6",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:函数介绍</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac93628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfffb4e",
   "metadata": {},
   "source": [
    "1)Counter类的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c3787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({133: 2, 132: 1})\n",
      "0\n",
      "2\n",
      "dict_values([2, 1])\n",
      "[133, 132]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[0,133,1],[0,132,0],[0,133,0]])\n",
    "#使用Counter类对数组第2列进行遍历\n",
    "counter = Counter(x[:,1])\n",
    "#第2列中有1个132和2个133，输出该counter对象可以统计这列的数值情况，便于之后的统计\n",
    "print(counter)\n",
    "#因为第2列中没有为0的值，所以返回0\n",
    "print(counter[0])\n",
    "#因为第2列中有2个133，所以返回2\n",
    "print(counter[133])\n",
    "#一般的字典操作方法都能在该类中使用，例如可以通过values函数返回该列的非重复值的个数，方便对某列的非重复值的个数进行查看\n",
    "print(counter.values())\n",
    "#可以输出所有非重复值\n",
    "print(list(counter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc27d84",
   "metadata": {},
   "source": [
    "2)使用numpy中的unique实现非重复值的提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a954859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1 132 133] [132 133]\n",
      "Counter({133: 2, 132: 1})\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([132, 133])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[0,133,1],[0,132,0],[0,133,0]])\n",
    "a=np.unique(x[:])\n",
    "a1=np.unique(x[:,1])\n",
    "counter = Counter(x[:,1])\n",
    "print(a,a1)\n",
    "print(counter)\n",
    "print(len(a))\n",
    "a1\n",
    "# print(math.log2(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b28b2f",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe46fb",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">该数据集(train_titanic.csv)为分类数据集，为泰坦尼克号的部分乘客信息以及最后是否生还。包括了四个属性值以及一个标记属性(即为Survived类型,代表是否生还),属性信息分别为Sex(性别)，sibsp(堂兄弟妹个数)，Parch(父母与小孩的个数)，Pclass(乘客等级)  \n",
    "其中该数据集无缺失值和异常值，且所有连续变量已自动转换为离散变量,标记(Survived类型)也自动转变为离散变量0和1，所以你无需进行数据预处理，可以直接使用该数据集。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc6ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570e618",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 使用pandas库将训练数据集'train_titanic.csv'载入到Dataframe对象中</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b1263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_frame = pd.read_csv('train_titanic.csv')\n",
    "# x = np.array([[0],[1]])\n",
    "# counter = Counter(x[:,0])\n",
    "# print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3bc41",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 编写函数，给定任何标记数组计算其信息熵  \n",
    "    输入：标记数组  \n",
    "    输出：该数组对应的信息熵  \n",
    "    计算信息熵公式:\n",
    "某数组包含K个不同的取值，样本为第k(k=1,2,...,K)个值的数量所占比例为p_k,则其信息熵为$$Ent=-\\sum_{k=1}^K p_k log_2 p_k$$</span>\n",
    "    \n",
    "    \n",
    "<span style=\"color:purple\">例:  \n",
    "    输入:[[0],[1]]   \n",
    "    输出:(-$\\frac{1}{2}$ $log_2$ $\\frac{1}{2}$)+(-$\\frac{1}{2}$ $log_2$ $\\frac{1}{2}$)=1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa569aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label):\n",
    "    label = label.reshape(len(label),1)\n",
    "    counter = Counter(label[:,0])\n",
    "    a=np.unique(label[:,0])\n",
    "    ent=0\n",
    "    m = len(label)\n",
    "    for i in range(len(a)):\n",
    "        ent -= counter[a[i]]/m*np.log2(counter[a[i]]/m)\n",
    "    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77ab84",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 编写函数，函数功能为将所给的数据集按照指定维度dimension进行划分为若干个不同的数据集  \n",
    "    【输入】：属性集合，标记集合，维度索引  \n",
    "    【输出】：划分后所得到的子树属性集合，子树标记集合</span>\n",
    "\n",
    "<span style=\"color:purple\">例子:  \n",
    "    【输入】:feature(属性值集合):[[0,0,0],[0,0,1],[1,0,2]]  \n",
    "    label(标记集合):[[0],[1],[2]]  \n",
    "    划分维度:0</span>  \n",
    "    \n",
    "<span style=\"color:purple\">【输出】:[[0,0,0],[0,0,1]]和[[1,0,2]]  \n",
    "    [[0],[1]]和[[2]]  \n",
    "    tips:即将feature按其第0维度进行划分，由于feature的0维有0和1两个不同的数值，所以feature划分为[[0,0,0],[0,0,1]]和[[1,0,2]]，label划分为[[0],[1]]和[[2]]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1460ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(feature, label, dimension):\n",
    "    label = label.reshape(len(label),1)\n",
    "    a=np.unique(feature[:,dimension])\n",
    "#     split_feature = np.empty(len(a))\n",
    "    split_feature = []\n",
    "    split_label = []\n",
    "    for i in range(len(a)):\n",
    "        split_feature.append([])\n",
    "        split_label.append([])\n",
    "    for i in range(len(label)):\n",
    "        for j in range(len(a)):\n",
    "            if feature[i,dimension]==a[j]:\n",
    "                split_feature[j].append(feature[i,:])\n",
    "                split_label[j].append(label[i,:])\n",
    "#         split_feature[j] = np.array(split_feature[j])\n",
    "#         split_label[j] = np.array(split_label[j])\n",
    "    for i in range(len(a)):\n",
    "        split_feature[i] = np.array(split_feature[i])\n",
    "        split_label[i] = np.array(split_label[i])\n",
    "    split_feature = np.array(split_feature)\n",
    "    split_label = np.array(split_label)\n",
    "    return split_feature,split_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0230f",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 编写函数，函数功能为进行【一次】决策树的结点划分，遍历找出该属性集合中信息增益(使用ID3算法中的公式计算)【最大】的属性  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的最佳信息增益，最佳划分维度  \n",
    "    计算信息增益公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,这里取其中一个属性类型feature,该特征包含V个不同的取值，属性值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^VD^v=|D|)$,则该属性值对应的信息增益为为$$Gain(D,feature)=Ent(D)-\\sum_{v=1}^K \\frac{|D^v|}{D} Ent(D^v)$$\n",
    "所以该函数中你需要计算出每个属性值的信息增益并输出，然后返回最大的信息增益并返回该特征的维数以及最大的信息增益值</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_split_ID3(feature, label):\n",
    "    best_entropy = -100\n",
    "    best_dimension = -1\n",
    "\n",
    "    tot = entropy(label)\n",
    "#     print(feature.shape)\n",
    "#     print(label.shape)\n",
    "    for i in range(len(feature[0])):\n",
    "        tem = tot\n",
    "        \n",
    "        split_feature,split_label=split(np.c_[feature,label],label,i)\n",
    "        for j in range(len(split_label)):\n",
    "            tem-=len(split_label[j])/len(label)*entropy(split_label[j])\n",
    "        if tem>best_entropy:\n",
    "            best_entropy=tem\n",
    "            best_dimension=i\n",
    "    return best_entropy, best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8593e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">5) 编写函数，函数功能为进行【一次】决策树的结点划分，遍历找出该属性集合中信息增益率(使用C4.5算法中的公式计算)【最大】的属性  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的信息增益率，最佳维度  \n",
    "    计算信息增益率公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,这里取其中一个属性类型feature,该属性包含V个不同的取值，属性值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^V|D^v|=|D|)$,该属性本身的信息熵为Ent(feature),则该属性值对应的信息增益率为$$Gain\\_ratio(D,feature)=\\frac{Gain(D,feature)}{Ent(feature)}$$\n",
    "所以该函数中你需要输出每个特征的信息增益率，之后返回最大的信息增益率对应的属性维数以及最大的信息增益率</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d51379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_split_C4_5(feature, label):\n",
    "    best_entropy = -100\n",
    "    best_dimension = -1\n",
    "\n",
    "    tot = entropy(label)\n",
    " \n",
    "    for i in range(len(feature[0])):\n",
    "        tem = tot\n",
    "        entf = entropy(feature[:,i])\n",
    "        split_feature,split_label=split(np.c_[feature,label],label,i)\n",
    "        \n",
    "        for j in range(len(split_label)):\n",
    "            tem-=len(split_label[j])/len(label)*entropy(split_label[j])\n",
    "        tem /= entf\n",
    "        if tem>best_entropy:\n",
    "            best_entropy=tem\n",
    "            best_dimension=i\n",
    "    return best_entropy, best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40f45a",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">6) 编写函数，进行【一次】决策树的结点划分，遍历找出该属性集合中基尼系数(使用CART算法中的公式计算)最小的属性以及最佳的划分值  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的最佳的基尼系数，最佳维度，最佳划分值  \n",
    "    计算基尼系数公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,该集合中样本标记类别总共有K类，第k类样本所占比例为$p_k$(k=1,2,..,K)则该数据集对应的基尼系数为$$Gini(D)=1-\\sum_{k=1}^K{p_k}^2$$  \n",
    "    而取其中一个属性类型feature，选定该类型的一个值value，根据feature这个属性是否为value将数据集分为两个子集$D_1$和$D_2$,则该属性feature对应的基尼系数为$$Gini\\_index(D,feature)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$$\n",
    "所以该函数中你需要首先找出每列中的非重复值，之后根据该列的非重复值进行分类，计算出该列中以该值进行分类的基尼系数，计算出每个属性的每个非重复值的基尼系数，之后找到最小的基尼系数对应的属性维数以及对应的分类值</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d073721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_split_CART(feature, label):\n",
    "    d = len(feature)\n",
    "    best_entropy = 100\n",
    "    best_dimension = -1\n",
    "    best_value = -1\n",
    "    for i in range(len(feature[0])):\n",
    "        counter = Counter(feature[:,i])\n",
    "        a=np.unique(feature[:,i])\n",
    "        \n",
    "        for k in a:\n",
    "            tem10 = 0\n",
    "            tem11 = 0\n",
    "            tem20 = 0\n",
    "            tem21 = 0\n",
    "            for j in range(d):\n",
    "                if feature[j,i] == k:\n",
    "                    if label[j] == 0:\n",
    "                        tem10 += 1\n",
    "                    else:\n",
    "                        tem11 += 1\n",
    "                else:\n",
    "                    if label[j] == 0:\n",
    "                        tem20 += 1\n",
    "                    else:\n",
    "                        tem21 += 1\n",
    "            tem10 /= counter[k]\n",
    "            tem11 /= counter[k]\n",
    "            tem20 /= (d-counter[k])\n",
    "            tem21 /= (d-counter[k])\n",
    "            gini = counter[k]/d*(1-tem10*tem10-tem11*tem11)+(d-counter[k])/d*(1-tem20*tem20-tem21*tem21)\n",
    "            \n",
    "            if gini < best_entropy:\n",
    "                best_entropy = gini\n",
    "                best_dimension = i\n",
    "                best_value = k\n",
    "            \n",
    "    return best_entropy,best_dimension,best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdc9f0",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">7) 应用之前你在第4、5、6个部分编写的三个函数，在训练数据集'train_titanic.csv'上依次使用这些函数进行【一次】结点划分，并输出对应的最佳属性维数以及相应的信息增益值/信息增益率/(基尼系数和分类值)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8769cb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2318094843987734, 0)\n",
      "(0.24383747685657423, 0)\n",
      "(0.32380857047523715, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "D = np.array(train_frame)\n",
    "feature = D[:,0:D.shape[1]-1]\n",
    "label = D[:,D.shape[1]-1:D.shape[1]]\n",
    "print(one_split_ID3(feature, label))\n",
    "print(one_split_C4_5(feature, label))\n",
    "print(one_split_CART(feature, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c11456",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d0594",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea6656",
   "metadata": {},
   "source": [
    "二、本周不需要提交实验报告，这周的实验课内容和下周的实验课内容汇总到同一个实验报告中，于下下周五实验课(3月31号前)上课前提交报告  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53b7c6",
   "metadata": {},
   "source": [
    "实验四(决策树)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/64eccd2dd9584125be510bb68435b0c6/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5144461",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
