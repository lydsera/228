{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验四:决策树(2)</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca268aef",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365ec76",
   "metadata": {},
   "source": [
    "本次实验承接上次实验，用【ID3】算法实现一棵完整的决策树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedc8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6819a7",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 整理上次实验的代码，编写函数，【从属性集A中】寻找使得信息增益最大的属性   \n",
    "    输入：数据集D、属性集A   \n",
    "    输出：最佳划分的属性(维度)     \n",
    "    计算信息增益公式:  \n",
    "    某数据集D有若干特征值以及对应的标签值，其总样本大小为|D|,这里取其中一个特征类型feature,该特征包含V个不同的取值，特征值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^VD^v=|D|)$,则该特征值对应的信息增益为$$Gain(D,feature)=Ent(D)-\\sum_{v=1}^K \\frac{|D^v|}{D} Ent(D^v)$$</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b55657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label):\n",
    "    label = np.array(label).reshape(len(label),1)\n",
    "#     print(label.shape)\n",
    "#     print(label)\n",
    "    counter = Counter(label[:,0])\n",
    "    print(list(counter))\n",
    "    a=np.unique(label[:,0])\n",
    "    ent=0\n",
    "    m = len(label)\n",
    "    for i in range(len(a)):\n",
    "        ent -= counter[a[i]]/m*np.log2(counter[a[i]]/m)\n",
    "    return ent\n",
    "\n",
    "def split(feature, label, dimension):\n",
    "\n",
    "    a=np.unique(feature[:,dimension])\n",
    "    split_feature = []\n",
    "    split_label = []\n",
    "    for j in range(len(a)):\n",
    "        split_feature.append([])\n",
    "    for j in range(len(a)):\n",
    "        tem1 = []\n",
    "        tem2 = []\n",
    "        for i in range(len(label)):\n",
    "            \n",
    "            if feature[i,dimension]==a[j]:\n",
    "                \n",
    "                tem1.append(feature[i])\n",
    "                \n",
    "                tem2.append(label[i])\n",
    "                \n",
    "                break\n",
    "        split_feature.append(tem1)\n",
    "        split_label.append(tem2)\n",
    "#     print(split_label)        \n",
    "    return split_feature,split_label\n",
    "\n",
    "\n",
    "def best_split(D, A):\n",
    "    \n",
    "    best_entropy = -10000\n",
    "    best_dimension = -1\n",
    "    n = D.shape[1]-1\n",
    "    \n",
    "    tot = entropy(D[:,n:n+1])\n",
    "    \n",
    "    for i in A:\n",
    "        \n",
    "        tem = tot\n",
    "        split_feature,split_label=split(D[:,0:n],D[:,n:n+1],i)\n",
    "        \n",
    "#         split_feature = np.array(split_feature)\n",
    "#         split_label = np.array(split_label)\n",
    "        for j in range(len(split_label)):\n",
    "            tem-=entropy(split_label[j])\n",
    "        if tem>best_entropy:\n",
    "            best_entropy=tem\n",
    "            best_dimension=i\n",
    "        \n",
    "    return best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5da06",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 完成DTree类中的TreeGenerate、train函数以完成决策树的构建。并完成DTree类中的predict函数来用构建好的决策树来对测试数据集进行预测并输出预测准确率。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d03dbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树结点类\n",
    "class Node:\n",
    "    def __init__(self, isLeaf=True, label=-1, index=-1):\n",
    "        self.isLeaf = isLeaf # isLeaf表示该结点是否是叶结点\n",
    "        self.label = label # label表示该叶结点的label（当结点为叶结点时有用）\n",
    "        self.index = index # index表示该分支结点的划分属性的序号（当结点为分支结点时有用）\n",
    "        self.children = {} # children表示该结点的所有孩子结点，dict类型，方便进行决策树的搜索\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        self.children[val] = node #为当前结点增加一个划分属性的值为val的孩子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12e76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树类\n",
    "class DTree:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None #决策树的根结点\n",
    "        self.possible_value = {} # 用于存储每个属性可能的取值\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    TreeGenerate函数用于递归构建决策树，伪代码参照课件中的“Algorithm 1 决策树学习基本算法”\n",
    "    '''\n",
    "    def TreeGenerate(self, D, A):\n",
    "\n",
    "        # 生成结点 node\n",
    "        node = Node()\n",
    "        \n",
    "        \n",
    "        counter = Counter(D[:,D.shape[1]-1])\n",
    "        # if D中样本全属于同一类别C then\n",
    "        #     将node标记为C类叶结点并返回\n",
    "        # end if\n",
    "        if counter[0] == len(D):\n",
    "            node.label = 0\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        elif counter[1] == len(D):\n",
    "            node.label = 1\n",
    "            node.isLeaf = True \n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if A = Ø OR D中样本在A上取值相同 then\n",
    "        #     将node标记叶结点，其类别标记为D中样本数最多的类并返回\n",
    "        # end if\n",
    "  \n",
    "        if (not len(A)) or len(np.unique(D[:,4:5]))==1:\n",
    "            if counter[0]>counter[1]:\n",
    "                node.label = 0\n",
    "            else:\n",
    "                node.label = 1\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 从A中选择最优划分属性a_star\n",
    "        # （选择信息增益最大的属性，用到上面实现的best_split函数）\n",
    "      \n",
    "        a_star = best_split(D, A)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for a_star 的每一个值a_star_v do\n",
    "        #     为node 生成每一个分支；令D_v表示D中在a_star上取值为a_star_v的样本子集\n",
    "        #     if D_v 为空 then\n",
    "        #         将分支结点标记为叶结点，其类别标记为D中样本最多的类\n",
    "        #     else\n",
    "        #         以TreeGenerate(D_v,A-{a_star}) 为分支结点\n",
    "        #     end if\n",
    "        # end for\n",
    "        tem = Counter(D[:,a_star])\n",
    "        tem1 = np.unique(D[:,a_star])\n",
    "        node.isLeaf = False\n",
    "        node.index = a_star\n",
    "#         print(tem.values())\n",
    "#         print(tem)\n",
    "        for a_star_v in tem1:\n",
    "#             print(A)\n",
    "#             print(a_star_v)\n",
    "            newnode = Node(False)\n",
    "            if(tem[a_star_v]==0):\n",
    "                newnode.isleaf = True\n",
    "                newnode.label = 0\n",
    "            else:\n",
    "                D_v = np.array\n",
    "                for i in range(len(D)):\n",
    "                    if D[i,a_star] == a_star_v:\n",
    "                        D_v = np.r_[D_v,D[i,:]]\n",
    "                D_v = D_v.reshape(len(D_v),1)\n",
    "#                 print(D_v.shape)\n",
    "                A.remove(a_star)\n",
    "                newnode = self.TreeGenerate(D_v,A)\n",
    "            node.children[a_star_v] = newnode\n",
    "        \n",
    "        \n",
    "        return node\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    train函数可以做一些数据预处理（比如Dataframe到numpy矩阵的转换，提取属性集等），并调用TreeGenerate函数来递归地生成决策树\n",
    "    '''\n",
    "    def train(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        A = set(range(D.shape[1] - 1)) # 属性集A\n",
    "        A = list(A)\n",
    "#         #记下每个属性可能的取值\n",
    "        for every in A:\n",
    "            self.possible_value[every] = np.unique(D[:, every])\n",
    "        \n",
    "        self.tree_root = self.TreeGenerate(D, A) # 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    predict函数对测试集D进行预测， 并输出预测准确率（预测正确的个数 / 总数据数量）\n",
    "    '''\n",
    "    def predict(self, D):\n",
    "        D = np.array(D) # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        correct = 0\n",
    "#         #对于D中的每一行数据d，从当前结点x=self.tree_root开始，当当前结点x为分支结点时，\n",
    "#         #则搜索x的划分属性为该行数据相应的属性值的孩子结点（即x=x.children[d[x.index]]），不断重复，\n",
    "#         #直至搜索到叶结点，该叶结点的label就是数据d的预测label\n",
    "        for i in range(len(D)):\n",
    "            x = self.tree_root\n",
    "            d = D[i,:]\n",
    "            while x.isLeaf == True:\n",
    "                x=x.children[d[x.index]]\n",
    "            if x.label == d[len(d)-1]:\n",
    "                correct += 1\n",
    "        return correct/len(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "703553c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[<built-in function array>, 0, 1, 3, 5, 4, 2, 8, 6, 9]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m dt \u001b[38;5;241m=\u001b[39m DTree()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 构建决策树\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 利用构建好的决策树对测试数据集进行预测，输出预测准确率（预测正确的个数 / 总数据数量）\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_titanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mDTree.train\u001b[1;34m(self, D)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m every \u001b[38;5;129;01min\u001b[39;00m A:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_value[every] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(D[:, every])\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeGenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mDTree.TreeGenerate\u001b[1;34m(self, D, A)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#                 print(D_v.shape)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m                 A\u001b[38;5;241m.\u001b[39mremove(a_star)\n\u001b[1;32m---> 83\u001b[0m                 newnode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeGenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m             node\u001b[38;5;241m.\u001b[39mchildren[a_star_v] \u001b[38;5;241m=\u001b[39m newnode\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mDTree.TreeGenerate\u001b[1;34m(self, D, A)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 从A中选择最优划分属性a_star\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# （选择信息增益最大的属性，用到上面实现的best_split函数）\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m a_star \u001b[38;5;241m=\u001b[39m \u001b[43mbest_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# for a_star 的每一个值a_star_v do\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#     为node 生成每一个分支；令D_v表示D中在a_star上取值为a_star_v的样本子集\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#     if D_v 为空 then\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#     end if\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# end for\u001b[39;00m\n\u001b[0;32m     62\u001b[0m tem \u001b[38;5;241m=\u001b[39m Counter(D[:,a_star])\n",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36mbest_split\u001b[1;34m(D, A)\u001b[0m\n\u001b[0;32m     42\u001b[0m best_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m n \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 45\u001b[0m tot \u001b[38;5;241m=\u001b[39m \u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m A:\n\u001b[0;32m     49\u001b[0m     tem \u001b[38;5;241m=\u001b[39m tot\n",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36mentropy\u001b[1;34m(label)\u001b[0m\n\u001b[0;32m      5\u001b[0m counter \u001b[38;5;241m=\u001b[39m Counter(label[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(counter))\n\u001b[1;32m----> 7\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m ent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\d2l-zh\\lib\\site-packages\\numpy\\lib\\arraysetops.py:263\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    261\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\d2l-zh\\lib\\site-packages\\numpy\\lib\\arraysetops.py:311\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    309\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    313\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "dt = DTree()\n",
    "\n",
    "# 构建决策树\n",
    "dt.train(train_frame)\n",
    "\n",
    "# 利用构建好的决策树对测试数据集进行预测，输出预测准确率（预测正确的个数 / 总数据数量）\n",
    "test_frame = pd.read_csv('test_titanic.csv')\n",
    "dt.predict(test_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f62e5",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1b059",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a115318",
   "metadata": {},
   "source": [
    "二、这两周的实验课内容汇总到同一个实验报告中，于下周五实验课(4月1号前)上课前提交报告  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2724b",
   "metadata": {},
   "source": [
    "实验四(决策树)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/fdadf5486c654f4caf451e1d2c019c07/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1352b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c7422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc441a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b28d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e108fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
